[{"categories":[],"content":"What do research crowdfunding, citizen science, and blockchain technologies have in common? They represent a fundamental shift away from centralized authority toward distributed decision-making. This same shift is now reaching the heart of academic governance: how we evaluate research.\nI attended a symposium at Kyoto University on their new research evaluation framework, COMON. As an outsider—a researcher studying peer review systems—I witnessed something that goes far beyond the “responsible metrics” discourse of DORA or the collaborative spirit of CoARA. This is not another call for better measurement. It is a restructuring of institutional relationships, built on recognition that universities must help research communities create entirely new resources rather than compete for a fixed pie.\nFrom Discovery to Audit: The First Transformation Scattered comparisons of publication counts began around 1910 [Narin, 1976], crystallizing into scientometrics as a formal discipline by the 1960s. Before the 1980s, evaluation served a clear purpose: discovering excellent work and maintaining scholarly quality. Peer review served as a self-regulatory mechanism. Evaluation occurred within disciplines, from an academic perspective, by those who understood the work.\nThe 1980s brought the first turning point. Research activity expanded dramatically while public funding growth slowed amid economic recession. The 1990s introduced New Public Management principles into research governance [Georghiou \u0026 Rossner, 2000; Irvine \u0026 Martin, 1984]. Evaluation pivoted from discovery to accountability. Taxpayers demanded explanations. Policymakers demanded metrics. The question changed from “How do we find great research?” to “How do we prove we’re spending wisely?”\nThe consequences are now visible globally. The Trump administration’s assault on university autonomy starkly revealed this audit paradigm’s vulnerabilities. In Japan, incorporating national universities as independent administrative agencies appeared to reduce government intervention, which turned out that universities remained dependent on block grants while reporting burdens exploded. In the EU, Horizon Europe struggles to balance excellence metrics with geographic and institutional diversity—revealing tensions between accountability demands and research reality. China’s centralized S\u0026T planning faces growing recognition that top-down control stifles the innovation it seeks to foster. Autonomy in name; surveillance in practice.\nLong Struggle: Fleeing the Metrics Tsunami The 2010s brought growing recognition of these limitations. DORA (the San Francisco Declaration on Research Assessment) emerged as a response to metric abuse—but remained firmly within the accountability framework. It called for responsible metrics, not rejection of the audit paradigm itself. This is crucial: responsible metrics represent the second stage’s attempt at self-correction, not transcendence.\nMultiple forces converged to make this insufficient. Change accelerated. Uncertainty rose. Multi-year review cycles like the UK’s Research Excellence Framework struggled to keep pace. Top-down national research strategies faced recognized limitations in unpredictable environments.\nInterdisciplinarity complicated matters further. When projects span multiple fields, no single researcher can comparatively evaluate them. Who judges collaborations among climate scientists, AI researchers, and political economists against traditional disciplinary standards? UNESCO’s Open Science declaration acknowledged this: different fields produce different outputs. Publications dominate some disciplines. Others value practical software, conference presentations, or scholarly monographs. Imposing a single evaluation axis invites dysfunction.\nYet universities faced a paradox. Without common metrics, how can they allocate block funding across faculties? This tension drove CoARA’s (Coalition for Advancing Research Assessment) emergence as a bridge. While rooted in concerns about metric diversity, it gestured toward something more fundamental: recognition that research outcomes are inherently diverse and should be celebrated as such. CoARA’s collaborative exploration, involving numerous universities, has been developing new evaluation paradigms. But it remained largely within existing accountability structures.\nFrom Audit to Dialogue: COMON’s Radical Vision COMON represents these efforts crystallizing into something genuinely different. Kyoto University’s framework refuses to use evaluation results for funding allocation—a deliberate break from the accountability paradigm that defines Stage 2. Instead, it shifts institutional relationships from control to capacity-building.\nOne researcher from Kyoto University explained COMON through the Paris Agreement framework. The climate accord emerged from lessons learned: the Kyoto Protocol’s failure came from imposing uniform targets on nations with vastly different circumstances, producing resentment and resistance. The Paris Agreement enables voluntary participation. Each nation sets its own commitments while contributing to a collective goal. Unity through diversity, coordination without coercion.\nCOMON adopts this structure, but goes further. It defines quality research through five dimensions including diversity and research not yet visible. Crucially, COMON explicitly prohibits using these evaluations for funding allocation. Indicators inevitably produce gaming when tied to resources.\nBut the deeper transformation lies in institutional relationships. The university’s role shifts from allocation and audit to capacity-building. It provides minimum funding and focuses on helping each faculty and research project attract resources independently—through grants, industry partnerships, even crowdfunding. This support extends beyond money to researcher development, academic society formation, and communications capacity.\nHere is what makes this radical: the goal is not optimizing distribution of a fixed resource pool. In an era of increasing complexity and diversity, the aim is transforming each organizational unit—each faculty, each project—into an entity capable of creating new resources rather than competing for limited existing ones. This requires each unit to reflect on where they currently stand and build evaluation frameworks suited to their specific contexts. The university enables this self-directed development through resources like University Research Administrators (URAs).\nThis is what “dialogue” means in COMON’s vision. It is not simply about emphasizing qualitative assessment over quantitative metrics for individual projects. It is about fostering disciplinary consensus and a sense of belonging—something that cannot emerge from centralized metrics. When faculties and projects collaboratively determine what they need to do, how they define success, and how they will build capacity, they reconstruct the shared purpose that audit culture eroded. This path forward is uncertain and will likely be difficult for all involved. But unlike superficial reforms, it addresses the root cause.\nThis is not a rosy vision of smooth transition. What Kyoto University proposes is difficult, uncertain work. It means faculties and projects must develop new capabilities. It means researchers must think differently about how they build support and demonstrate value. It means universities must radically reconceive their role from gatekeepers to enablers.\nThis matters because research evaluation shapes research itself. When competition for fixed resources dominates, collaboration suffers.\nCOMON asks whether research communities can define and pursue excellence when given tools, resources, and freedom rather than surveillance. Whether universities can shift from controlling to enabling. Whether decentralized evaluation can maintain quality and accountability. These questions have no guaranteed answers. Some faculties and projects will struggle or fail. Universities will face pressure to reassert central control when outcomes seem unclear.\nThis is not a quiet paradigm shift. It is a loud one—if you know what to listen for.\n","date":"2025-10-12","lastmod":"2025-10-12","permalink":"http://localhost:1313/posts/research_evaluation_reform/","summary":"What do research crowdfunding, citizen science, and blockchain technologies have in common? They represent a fundamental shift away from centralized authority toward distributed decision-making. This same shift is now reaching the heart of academic governance: how we evaluate research.\nI attended a symposium at Kyoto University on their new research evaluation framework, COMON. As an outsider—a researcher studying peer review systems—I witnessed something that goes far beyond the “responsible metrics” discourse of DORA or the collaborative spirit of CoARA. This is not another call for better measurement. It is a restructuring of institutional relationships, built on recognition that universities must help research communities create entirely new resources rather than compete for a fixed pie.\n","tags":[],"title":"From Audit to Dialogue: Research Evaluation's Radical Turn","url":"/posts/research_evaluation_reform/"},{"categories":[],"content":"By defining “push” in academic citation, learning from open-source software (OSS) development, we demonstrate citation metrics can incentivise reviewer as repository owners, under open participatory peer review. Potential drawbacks and countermeasures are also discussed.\n","date":"2024-12-02","lastmod":"2024-12-02","permalink":"http://localhost:1313/posts/incentivised-open-peer-review/","summary":"By defining “push” in academic citation, learning from open-source software (OSS) development, we demonstrate citation metrics can incentivise reviewer as repository owners, under open participatory peer review. Potential drawbacks and countermeasures are also discussed.\n","tags":[],"title":"[Contributed Talk] Incentivised Open Participated Peer Review without Rewarding","url":"/posts/incentivised-open-peer-review/"},{"categories":[],"content":"title: “Scientists Have an Inherent Prioritized Queue in Selecting Collaborations” excerpt: The paper analyzes the temporal dynamics of co-authorship in scientific publications, finding a fat-tailed interval distribution between recurring collaborations, which can be explained by a proposed priority selection model simulating multi-agent team dynamics based on co-authorship willingness. The findings suggest non-Poisson activity patterns in scientific collaborations.\nvenue: ‘ICSSI’\nurl: https://icssi2024.org/ (the website is no longer available)\npaperurl: ‘http://academicpages.github.io/files/paper3.pdf'\ntype: ‘Contributed Talk’\n","date":"2024-07-01","lastmod":"2024-07-01","permalink":"http://localhost:1313/posts/icssi-2024/","summary":"title: “Scientists Have an Inherent Prioritized Queue in Selecting Collaborations” excerpt: The paper analyzes the temporal dynamics of co-authorship in scientific publications, finding a fat-tailed interval distribution between recurring collaborations, which can be explained by a proposed priority selection model simulating multi-agent team dynamics based on co-authorship willingness. The findings suggest non-Poisson activity patterns in scientific collaborations.\nvenue: ‘ICSSI’\nurl: https://icssi2024.org/ (the website is no longer available)\npaperurl: ‘http://academicpages.github.io/files/paper3.pdf'\ntype: ‘Contributed Talk’\n","tags":[],"title":"[Contributed Talk] Scientists Have an Inherent Prioritized Queue in Selecting Collaborations","url":"/posts/icssi-2024/"},{"categories":[],"content":"By defining “push” in academic citation, learning from open-source software (OSS) development, we demonstrate citation metrics can incentivise reviewer as repository owners, under open participatory peer review. Potential drawbacks and countermeasures are also discussed.\nvenue: ‘ScisciConference’ paperurl: ‘https://sciscijp.github.io/scisciconfJP2024/program/' type: ‘Poster Presentation’\n","date":"2024-03-17","lastmod":"2024-03-17","permalink":"http://localhost:1313/posts/oss-peer-review/","summary":"By defining “push” in academic citation, learning from open-source software (OSS) development, we demonstrate citation metrics can incentivise reviewer as repository owners, under open participatory peer review. Potential drawbacks and countermeasures are also discussed.\nvenue: ‘ScisciConference’ paperurl: ‘https://sciscijp.github.io/scisciconfJP2024/program/' type: ‘Poster Presentation’\n","tags":[],"title":"Application of OSS Pull Requests to Academic Citation and Incentivise Public Participation Peer Review","url":"/posts/oss-peer-review/"},{"categories":[],"content":"I have contributed to ScisciConf. as a chief coder and superviser of scisci-handson. Codes are consists of 1. Data structure of OpenAlex, 2. Clustering and visualization of disciplines, 3. Research evaluation by Wu-disruptiveness index, 4. Researcher evaluation by h-index.\nvenue: ‘ScisciConference’ paperurl: ‘https://github.com/ScisciJP/scisciJP2024_tutorial' type: ‘Lecture’\nScience of Science Tutorial\n","date":"2024-03-16","lastmod":"2024-03-16","permalink":"http://localhost:1313/posts/science-of-science-tutorial/","summary":"I have contributed to ScisciConf. as a chief coder and superviser of scisci-handson. Codes are consists of 1. Data structure of OpenAlex, 2. Clustering and visualization of disciplines, 3. Research evaluation by Wu-disruptiveness index, 4. Researcher evaluation by h-index.\nvenue: ‘ScisciConference’ paperurl: ‘https://github.com/ScisciJP/scisciJP2024_tutorial' type: ‘Lecture’\nScience of Science Tutorial\n","tags":[],"title":"Science of Science Tutorial","url":"/posts/science-of-science-tutorial/"},{"categories":[],"content":"You can see details here\nBuild a better ecosystem of science and academia, together. We are inviting you to the \"Bento-kai,\" a lunchtime study group: As we aim to innovate further and enhance research capabilities, we face many daily challenges regarding the mechanisms of science and academia. To address these, efforts have begun actively across industry, government, and academia to form communities, design policies and systems, and develop services. However, given the complexity of the challenges we face, you may experience difficulties and frustrations in your activities. We define endeavors that tackle challenges in science and academia as \"Metascience,\" and with the aim of sharing practical knowledge surrounding Metascience and building an organic space for connections among participants, we have launched \"Bento-kai,\" a \"brown-bag\" style study group.\nNagata Kazumasa, Tedzuka Akane, Nakamura Kotaro, Etori Shogo\n","date":"2023-08-20","lastmod":"2023-08-20","permalink":"http://localhost:1313/posts/bentokai-2023aug/","summary":"You can see details here\nBuild a better ecosystem of science and academia, together. We are inviting you to the \"Bento-kai,\" a lunchtime study group: As we aim to innovate further and enhance research capabilities, we face many daily challenges regarding the mechanisms of science and academia. To address these, efforts have begun actively across industry, government, and academia to form communities, design policies and systems, and develop services. However, given the complexity of the challenges we face, you may experience difficulties and frustrations in your activities. We define endeavors that tackle challenges in science and academia as \"Metascience,\" and with the aim of sharing practical knowledge surrounding Metascience and building an organic space for connections among participants, we have launched \"Bento-kai,\" a \"brown-bag\" style study group.\n","tags":[],"title":"Bento-kai: Making Better Science and Academic Ecosystem","url":"/posts/bentokai-2023aug/"},{"categories":[],"content":"venue: ‘DeSciTokyo Conference’ url: ‘https://desci-tokyo.jp/' type: ‘Contributed Talk’\n","date":"2023-04-16","lastmod":"2023-04-16","permalink":"http://localhost:1313/posts/desci-2023/","summary":"venue: ‘DeSciTokyo Conference’ url: ‘https://desci-tokyo.jp/' type: ‘Contributed Talk’\n","tags":[],"title":"[Contributed Talk] The Age of Anticipation and the Better Way to Share Science","url":"/posts/desci-2023/"},{"categories":[],"content":"Science is everywhere. From choosing the correct shampoo for your hair, to finding a single equation for whole universe. So understanding the mechanism behind the science is critical. This is where the “science of science” comes in. The discipline must aim to altering every obsolete mechanism of producing human (include other intelligent agents) knowledge. It’s like you are a factory owner who replaces an old manufacturing machine with a brand new one. It now ceases less frequent, works more efficiently, and understand your need better. You can now produce more with less.\nScience is an evolutionary process. Knowledge grows on its direct antecedents, and a mixture of diverse (yet close enough so that they can breed) intelligence produce fitter individuals. Therefore designing the fitness landscape of knowledge is crucial.\nInformation quality control is essential for distributed science. This is why I’m doing research on distributed knowledge productions and peer review innovations. Peer review is a selection process to determine which knowledge should be valued. We need a comprehensive understanding about what forms and updates the consensus within scientific communities. The main contribution of my research is “push citation”, a reversed citation from prior work to newer, combined with a improvement proposals for the prior research. For more detail, visit “Works” page.\nGet in touch with any of the following contacts:\nt.miura@gnt.place isakata@ipr-ctr.t.u-tokyo.ac.jp ","date":"2022-09-02","lastmod":"2022-09-02","permalink":"http://localhost:1313/posts/academic-github/","summary":"Science is everywhere. From choosing the correct shampoo for your hair, to finding a single equation for whole universe. So understanding the mechanism behind the science is critical. This is where the “science of science” comes in. The discipline must aim to altering every obsolete mechanism of producing human (include other intelligent agents) knowledge. It’s like you are a factory owner who replaces an old manufacturing machine with a brand new one. It now ceases less frequent, works more efficiently, and understand your need better. You can now produce more with less.\n","tags":[],"title":"Building Academic GitHub","url":"/posts/academic-github/"}]